{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de stationnarité & fit with good modele selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cours : Séries Temporelles et Modèles ARMA\n",
    "\n",
    "## 1. Conditions de Stationnarité et Dépendance Faible\n",
    "\n",
    "### Stationnarité\n",
    "Une série temporelle est **stationnaire** si elle respecte les trois conditions suivantes :\n",
    "1. **Moyenne constante** : \n",
    "   $E[X_t] = \\mu \\neq \\mu(t)$  \n",
    "   La moyenne est une constante finie indépendante du temps.\n",
    "   \n",
    "2. **Variance constante** : \n",
    "   $\\text{Var}[X_t] = \\sigma^2 \\neq \\sigma^2(t)$  \n",
    "   La variance est une constante finie indépendante du temps.\n",
    "\n",
    "3. **Covariance indépendante du temps** : \n",
    "   $\\text{Cov}(X_t, X_{t+h}) = \\gamma(h)$  \n",
    "   La covariance dépend uniquement du lag $h$, et non du temps $t$.\n",
    "\n",
    "### Dépendance faible\n",
    "Pour qu'une série soit faiblement dépendante :  \n",
    "$\\text{Corr}(X_t, X_{t+h}) \\to 0 \\text{ lorsque } h \\to \\infty$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Processus de Moyenne Mobile (MA)\n",
    "\n",
    "### Définition\n",
    "Un processus **MA(q)** s'écrit :  \n",
    "$\n",
    "X_t = \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\dots + \\theta_q \\epsilon_{t-q}\n",
    "$\n",
    "où $\\epsilon_t \\sim \\text{iid}(0, \\sigma^2)$.\n",
    "\n",
    "\n",
    "\n",
    "### Stationnarité\n",
    "Tout processus MA est toujours stationnaire.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Processus Auto-Régressif (AR)\n",
    "\n",
    "### Définition\n",
    "Un processus **AR(q)** s'écrit :  \n",
    "$\n",
    "X_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\dots + \\phi_q X_{t-q} + \\epsilon_t\n",
    "$\n",
    "où $\\epsilon_t \\sim \\text{iid}(0, \\sigma^2)$.\n",
    "\n",
    "### Stationnarité\n",
    "Un processus AR(q) est stationnaire si les racines du polynôme caractéristique :  \n",
    "$\n",
    "z^q - \\phi_1 z^{q-1} - \\phi_2 z^{q-2} - \\dots - \\phi_q = 0\n",
    "$\n",
    "sont **dans le cercle unité** $|z| < 1$.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Auto-Corrélation et Corrélation Partielle\n",
    "\n",
    "### Auto-Corrélation\n",
    "La fonction d'auto-corrélation totale mesure la corrélation entre $X_t$ et $X_{t-h}$ :\n",
    "$\n",
    "\\text{Corr}(X_t, X_{t-h}) = \\frac{\\text{Cov}(X_t, X_{t-h})}{\\sqrt{\\text{Var}[X_t] \\text{Var}[X_{t-h}]}}\n",
    "$\n",
    "\n",
    "### Corrélation Partielle\n",
    "La corrélation partielle à un lag $h$ est la corrélation entre $X_t$ et $X_{t-h}$, en contrôlant les effets des lags intermédiaires $(1, 2, \\dots, h-1)$. Elle peut être calculée en résolvant les **équations de Yule-Walker**.\n",
    "\n",
    "### Différences\n",
    "- **Corrélation totale** : Mesure l'effet global, y compris les dépendances indirectes.\n",
    "- **Corrélation partielle** : Mesure uniquement l'effet direct entre deux lags.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Valeurs-p (P-values)\n",
    "\n",
    "### Définition\n",
    "Une **valeur-p** représente la probabilité d'obtenir un résultat aussi extrême que celui observé, sous l'hypothèse nulle ($H_0$). Elle est liée à la fonction de répartition cumulative (CDF).\n",
    "\n",
    "### Exemple\n",
    "- Une pièce donnée produit 100% de faces sur 10 lancers : $p = 0.001$.  \n",
    "- Une autre pièce produit 51% de faces sur 1 million de lancers : $p \\approx 10^{-89}$.\n",
    "\n",
    "La valeur-p seule ne quantifie pas le biais ; il faut considérer les **intervalles de confiance**.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Processus ARMA\n",
    "\n",
    "### Définition\n",
    "Un processus **ARMA(p, q)** combine un modèle AR(p) et MA(q) :\n",
    "$\n",
    "X_t = \\phi_1 X_{t-1} + \\dots + \\phi_p X_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\dots + \\theta_q \\epsilon_{t-q}\n",
    "$\n",
    "\n",
    "### Propriétés\n",
    "- **Stationnarité** : Dépend des racines du polynôme AR.\n",
    "- **Invertibilité** : Dépend des racines du polynôme MA.\n",
    "\n",
    "### Exemple\n",
    "Les ventes $X_t$ peuvent être modélisées par un processus ARMA(1,1) :\n",
    "$\n",
    "X_t = 0.5 X_{t-1} + \\epsilon_t - 0.3 \\epsilon_{t-1}\n",
    "$\n",
    "- AR(1) pour les effets de fidélité.\n",
    "- MA(1) pour les effets résiduels immédiats.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Ce cours couvre les bases des modèles AR, MA, et ARMA, ainsi que des concepts clés comme la stationnarité, les corrélations et les valeurs-p. Ces outils sont essentiels pour l'analyse des séries temporelles et la modélisation prédictive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# ARIMA is more general model that include ARMA, it has 3 parameters\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# for Lyung Box test of autocorrelation\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# For the augmented Dickey-Fuller test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step by Step: \n",
    "1. Load the time-series\n",
    "2. Plot the time-series\n",
    "3. Check the stationarity\n",
    "4. If it is stationary, continue; if not, take the first difference and go to the step 3.\n",
    "5. Plot ACF and PACF \n",
    "6. Identify possible models (p,q)\n",
    "7. Fit all models that you identified\n",
    "8. Sort by AIC and measure ∆AIC. Exclude some models.\n",
    "9. Look at the confidence intervals on the estimated parameters (We would like to have all significants)\n",
    "10. Look at the ACF of the residues for the candidate models\n",
    "11. Test with Ljungbox if a serial correlation remains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check the stationarity\n",
    "\n",
    "on plot l'autocorrelation (ACF function) et on regarde.\n",
    "- si l'autocorrelation diminue doucement $=>$ marker of non-stationnarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1= # time serie\n",
    "\n",
    "sm.graphics.tsa.plot_acf(s1, lags=200)\n",
    "plt.ylabel(r'$lags$')\n",
    "plt.xlabel('ACF [$X_t$]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On s'en asure avec le Augmented Dickey-Fuller test to check for stationarity in the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le Augmented Dickey-Fuller test ( ADF tet) renvoie un tuple comprenant (Test Statistic ; P-value ; Number of lags Used ; Number of Observations used ; Critical values ; AIC maximum information Criterion)\n",
    "\n",
    "As example, if the ADF test for a time-serie give the values : \n",
    "1. Test statistic = -2.6645643672746036 \n",
    "2. p-value = 0.08037345141097707 it represent the probability of obtaining a test statistic at least as exreme as the one observed, assuming the null hypothesis at the 1% significante level \n",
    "3. Number of lags used = 4 \n",
    "4. Number of observations used = 9994 \n",
    "5. Critical Value = {'1%': -3.4310044907347454,'5%': -2.8618292459530794,'10%': -2.566923960483154}\n",
    "6. Maximum information criterion (AIC) = -63471.61889044968\n",
    "\n",
    "\n",
    "The statistic test = -2.6645643672746036 is greater than the critical value at the level of 1% = '1%': -3.4310044907347454 . So, we fail to reject the null hypothesis at the 1% significant level, indicating that the serie is non-stationnary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4. Differencing\n",
    "to adress the non-stationnarity in the contexte of ARIMA is used to differencing to turned into stationnary series. Differencing is a common method to make a time serie stationnary.\n",
    "\n",
    "We apply first-order differencing (d=1) and we check again the autocorrelation and we do the ADF test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=np.diff(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réitere jusqu'à ce que la p-value soit plus petite que la critical value.\n",
    "\n",
    "Le nombre de differenciation faites permet  d'identifier l'ARIMA Model $(p, \\text{nb de diff}, q)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 6. Identify possible models (p,q)\n",
    "the steps are <br> 1| Determine AR(p) (by analizing the ACF) and MA(q) (by analizing the PACF). Keep in mind that While the ACF suggests a higher-order MA component, it is often beneficial to start with simpler models. simpler model are easier to interpret and less prome to overfitting.<br> 2| Fit ARMA model to the differenced model using the different p, q identified earlly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(4,0),(1,1),(2,1),(1,2),(2,2)]\n",
    "\n",
    "M={}\n",
    "for p,q in models:\n",
    "    print(p,q)\n",
    "    ft=ARIMA(s1,order=(p,1,q)).fit()\n",
    "    M[p,q]=ft\n",
    "\n",
    "# Comparing Model Using AIC\n",
    "AIC = pd.DataFrame([((p,q),ft.aic) for (p,q), ft in M.items()], columns=['model','AIC'])\n",
    "print(AIC)\n",
    "\n",
    "AIC = AIC.assign(dAIC=(AIC.AIC - AIC.AIC.min()))\n",
    "AIC.sort_values('AIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models with dAIC<2 are considered indistinguishable from the best model <br> for dAIC < 7 it's ok but we prefere dAIC <2\n",
    "\n",
    "on analyse le meilleur model $(p, \\text{nb de diff}, q)$ \n",
    "\n",
    "We can simplificate the model by removing the non-significant constant term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_modèle=(p,d,q)\n",
    "model_ar4_no_const=ARIMA(s1, order=(4,0,0), trend='n')\n",
    "results_ar4_no_const=model_ar4_no_const.fit()\n",
    "results_ar4_no_const.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3| Model diagnostics : evaluated the model using various diagnostic\n",
    "\n",
    " We have to check the residuals to ensure that the model is appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r=results_ar4_no_const.resid\n",
    "\n",
    "sm.graphics.tsa.plot_acf(r, lags=20)\n",
    "plt.ylabel(r'$lags$')\n",
    "plt.xlabel('ACF [residus]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ljung-Box Test, used to confirm the adequacy of the model, we perform the ljung-box test on the residuals. this test check if there are any significant autocorrelations remaining in the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorr_ljungbox(r,lags=range(p+q+10), model_df=p+q,return_df=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
